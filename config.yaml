# Single source of truth for client + server config.
# Client section is served to the browser via /config.json.
client:
  # Send one frame every N milliseconds.
  sampling_ms: 150
  # Max in-flight ML requests from the client.
  max_in_flight: 2
  image:
    # jpeg or png
    format: jpeg
    # Only used for jpeg.
    jpeg_quality: 0.6
    # Client-side downscale before sending.
    max_width: 384
    max_height: 384

backend:
  # Base URL for ML inference service.
  base_url: https://amithadiraju1694-trifecta-backend.hf.space
  endpoints:
    # Relative paths for each model endpoint.
    seg: /run_segmentation
    face: /run_facemask
    text: /run_text
  # HTTP timeout for each inference request.
  timeout_ms: 1500
  # Server-side concurrency limit for outbound ML calls.
  max_concurrent_calls: 6
  # Use mock inference instead of calling ML service.
  use_mock: false
